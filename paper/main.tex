\documentclass[                                                                            
 reprint,                                                                                  
 amsmath,amssymb,                                                                          
 apsf
]{revtex4-2}

\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{booktabs}
\usetikzlibrary{arrows.meta, positioning}

\newcommand\todo[1]{\textcolor{red}{#1}}

\selectlanguage{english}

\definecolor{darkbg}{RGB}{15, 18, 25}
\definecolor{lighttext}{RGB}{247, 247, 255}
\definecolor{accent}{RGB}{211, 63, 73}


\date{\today}

\begin{document}

\title{``Misinformation'' Before and After 2016: the Impact of Its Satanic Panic Lineage}

\author{Ale}
\author{Danny}
\author{Julia}
\author{Jeremy}

\date{\today}
\begin{abstract}
    We trace the history of the term ``misinformation'' through the academic literature, with special focus on the years 2011-2023. In agreement with previous research, we find that the modern paradigm closely associated with the term formed around 2016. In analyzing the changing language in the literature before and after 2016, however, we find that, by beginning the story with social media, the field's history of itself leaves out important context. We fill that gap by identifying a consistent strand of ``misinformation'' research that can be traced back to the Satanic Panic of the 1980s, and we argue that today's research owes more to this intellectual lineage than is generally acknowledged. We conclude by drawing parallels between the Satanic Panic and today, and, similarly, between ``misinformation'' research then and now.
\end{abstract}

\maketitle

\section{Introduction}
\label{intro}
The term ``misinformation'' can be found in the academic literature of the 1950s, though it has none of the paradigm-defining weight it carries today. It is a relatively uncommon word, almost entirely used in medicine or public health. ``Combating Food Misinformation and Quackery''~\cite{HUENEMANN1956623}, for example, contains a familiar use of the term, and dates back to 1956. In the next year, however, we find ``Information and Misinformation Gained from Fasting Blood Sugar Alone in Diabetes Therapy''~\cite{johnInformationMisinformationGained1957}.

This trend continues through the 60s, with similar usage about the quality of information gained from some process, social or otherwise, albeit from increasingly diverse fields. Public health and medicine still dominate, but one finds, for example, ``A Model of the Soviet Firm''~\cite{gindinModelSovietFirm1970}, which discusses Soviet firms' attempts to correct for ``systematic misinformation'' by changing the incentives of compensation structure. In the 70s-90s, we start to see more specialized uses, with perhaps slightly divergent, more technical (if metaphorically-linked) meanings, like those associated with computation~\cite{michelCategoricalApproachDistributed1989}.

Among these usages comes that of that of the ``misinformation effect,'' in which ``[e]xposure to misinformation after an event takes place puts memory accuracy at risk''~\cite{loftus_misinformation_2024}. In \citet{loftus_reconstruction_1974}'s ``Reconstruction of automobile destruction: An example of the interaction between language and memory,'' we see the beginning of that paradigm, one that will identify itself closely with the term. Its experiments might involve asking a subject to recall something and, in the process, attempting to influence that memory in some way, perhaps by implication in the phrasing of her question~\cite{loftusPlantingMisinformationHuman2005b}. In a striking historical parallel to today, this ``misinformation'' paradigm played an important role in public life during the Satanic Panic of the 1980s and 1990s. We will discuss this usage at some length in Sections~\ref{results} and \ref{discussion}. %

In the early 2000s, public health practitioners become interested in ``infodemiology'', or ``the study of the determinants and distribution of health information and misinformation—which may be useful in guiding health professionals and patients to quality health information on the Internet''~\cite{eysenbachInfodemiologyEpidemiologyMisinformation2002}. From there, in what seems a logical next step, we see papers that study how (mis)information spreads during crises on social media, including epidemics~\cite{suttonBackchannelsFrontLines2008, chewPandemicsAgeTwitter2010, ohEXPLORATIONSOCIALMEDIA2010}. 

Finally, today, as we show in Section~\ref{results}, we have a new usage of ``misinformation,'' one focused on social media, and one that has entered into popular consciousness (e.g. see Figure ~\ref{fig:twitter}). It is not new that people say things that are not true, whether on social media or otherwise. That people often believe these things, both to our individual and collective detriments, is similarly unsurprising. What is new is that, since 2016, in both formal and informal settings, we have described this phenomenon with the term ``misinformation'' in a specific yet broad sense. 

In the academic literature, it has come to represent a new scientific paradigm, which, like any paradigm, comes with its own history and assumptions, and which has brought together several distinct strands of research under a shared framework and common language~\cite{kuhn_structure_1962}. As always, with a new paradigm's success comes a re-interpretation of previously-known facts. ``Misinformation'' has, for example, been used to describe events in Rome~\cite{posetti_short_2018}, and even the activities of fish and other animals~\cite{fahimipour_wild_2023, kongBriefNaturalHistory2025}. The paradigm's popularity means that such studies can garner attention in the popular press~\cite{times_evolution_2025,arnoldMisinformationInevitableBiological}.

Previous work shows, either implicitly or explicitly, that today's misinformation paradigm dates to roughly 2016, and that its existence is intertwined with the rise of social media~\cite{broda_misinformation_2024,donovan_express_2025}. Some argue this point in a critique of the paradigm\cite{miro-llinares_misinformation_2023}. These histories tend to begin with a general statement on the vast history of people saying and believing untrue things. They often cite technological upheavals in media as important factors, then specifically turn their focus to social media. 

We build upon those accounts of the post-paradigm history here. By analyzing academic papers published between 2011 and 2023 with the keyword ``misinformation'' in their metadata, we identify pre-2016 linguistic patterns unaccounted for in these histories~\cite{broda_misinformation_2024,donovan_express_2025}, and we connect them to the ``misinformation effect.'' We argue that today's misinformation research owes more to this lineage than is generally acknowledged~\cite{kuhn_structure_1962}. 

We conclude by noting the parallels between the ``misinformation effect'' research of the 1980s and today's. Both came about in moments of mass panic about evil forces doing harm to children, fueled by a changing media and political context. We are by no means the first to note the historical parallels between Qanon and the Satanic Panic, and we are much indebted to prior scholarship on this issue~\cite{hearst_qanon_2022}. Instead, our contribution is to note that, just as~\citet{hearst_qanon_2022} finds that modern conspiricism has roots in the Satanic Panic, so too can we trace the modern scientific response back to that of the 1980s. We hope that, by bringing this context to the fore, the scientific community can better navigate these moments of turbulence in the politically-contested nature of our shared reality.

\begin{figure}[H]
\label{fig:twitter}
\centering
\includegraphics[width=\linewidth]{misc-img/storywrangler.pdf}
\caption{Frequency of usage of the word ``misinformation'' on Twitter~\cite{alshaabi2021storywrangler}. Note the rise precisely at the US election in 2016.}
\end{figure}

\section{Data and Methods}

Our primary database is a Scopus export of all papers with ``misinformation'' in any metadata field from 2011–2023. We supplemented that with the opencitations.net API.

\subsection{Term Frequency}

We split our corpus into two case-insensitive bags of words (BOWs): One using all titles and abstracts from the years 2011-2015, and the second from 2017 onward. When tokenizing, we generated a list of the 400 most-frequent bigrams in our corpus and kept those as one token. We stripped punctuation, the most common stopwords, and some stopwords specific to our corpus \footnote{Those words are: elsevier, rights, reserved, mesh, taylor, francis, copyright, llc, bt, lftb, springer, ieee, information, misinformation. The last 2 were removed because they were present in almost every document.}

We calculated the frequency of every token in both BOWs, then chose the 9 smallest (i.e. most negative) and largest differences of frequency from the first to the second. We then classified all papers as having at least one word from either set or one of both, the results of which are in Figure \ref{fig:tf} and discussed in Section \ref{results}.


\subsection{Communities}

For the community labels, we created a network of papers with each edge representing an author; two papers are connected if they share an author. To avoid small-world problems from the small number of papers with many authors, the weight of the edge between two papers $P_1$ and $P_2$ was defined as

$$W(P_1, P_2) = \frac{1}{len(P_1.\text{authors}) \times len(P_2.\text{authors})}$$

We ran Louvain community detection to create the Community labels. Our community labels represent a community of papers linked by common authors, not a more traditional (and intuitive) community of authors linked by common papers. We are less interested in the institutional dynamics of misinformation scholars than the history of a concept.

Our algorithm labeled 8033 distinct communities. 6797 are communities of just one paper, and the average number of papers in a community is 1.66. We looked at the two biggest paper-communities in every year, as well as all the biggest communities in 2023, and analyzed the citation flows between communities, which we show in Figure \ref{fig:citations} and discuss in Section \ref{results}.

\section{Results}
\label{results}

After 2016, there is an explosion of the use of the word ``misinformation'' in academic literature. In 2011, the first year in our dataset, there were only 118 papers containing the term anywhere in their metadata. In 2023, there were 3380, or 28 times as many, and the post-2016 corpus contains 20 times as many papers as the pre-2016 one.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/fig.pdf}
\caption{Words with largest absolute frequency shifts before and after 2016 are on the right. We tagged all papers as having one from either or one of each. The top-left graph shows papers that have at least one word from that set of words as an annual percentage (some papers use both, so percentages do not add up to 100\%); the bottom one is the raw counts of all papers in the data.}
\label{fig:tf}
\end{figure}

Looking at tokens with the largest absolute frequency shift (Figure \ref{fig:tf}), the post-2016 words are those that we in 2025 expect in misinformation literature, like ``social media,'' ``pandemic,'' ``fake news,'' etc. As discussed in our introduction, these findings on the post-2016 explosion, as well as the topics of study (e.g. social media and the pandemic), are similar to those found in literature reviews~\cite{broda_misinformation_2024}, histories of misinformation~\cite{donovan_express_2025}, and academic summaries~\cite{posetti_short_2018} of the misinformation literature.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/first-communities.pdf}
\caption{The number of papers in the top 10 paper-communities throughout the duration of our dataset. Each community is labeled with its top TF-IDF terms.}
\label{fig:23comms}
\end{figure}


To our knowledge, however, the pre-2016 terms remain largely unexplained in misinformation histories and literature reviews. For example, in their literature review, \citet{broda_misinformation_2024} used a similar date range in their analysis as our own (2010-2021). Their dataset comes from Google Scholar, and they used keywords ``misinformation,'' ``disinformation,'' and ``fake news.'' They too find a similar explosion in the literature, and on a similar timeline, but their summary does not account for words like ``women,'' ``children,'' ``memory,'' and ``recall,'' though there are hints of the same phenomenon.\footnote{
This discrepancy seems to be, at least in part, an issue of data collection. They tried to find papers that had ``[a]t least one of the keywords ... present in title, keywords or abstract,'' but their Figure 1 shows virtually no papers until 2014. Even after, the number seems to be, at most, a couple dozen per year until past 2016. They also explain their difficulty in navigating Google Scholar's opaque algorithm, an increasingly common problem in computational studies~\cite{poudelCuratedRealitiesIntersection2025}. As discussed in Section~\ref{limitations}, this paper too suffers from a similar limitation, though from a different data source.
} When they break down the disciplines in which misinformation research is published, they find that the top 5 are Communication, Computer Science, Psychology, Political Science, and Economics. They note that the research in Psychology journals tends to focus on experiments, and that these experiments show broad themes. We discuss this in Section \ref{discussion}.


In short, we find that most summaries of the field tell its history as show in Figure \ref{fig:23comms}: They look at the most prominent strains of research today, then trace them back to their origin. Their analyses then flow from there. As a result, some histories explicitly define their inquiry to start with social media, defining a concept like ``misinformation-at-scale''~\cite{donovan_express_2025}.


\input{tables0.tex}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{network-img/4645.pdf}
\caption{An example of community \#4645's population (2011-2023), showing how human behavior research moves toward misinformation on social media over time.}
\label{fig:4645}
\end{figure}

This commonly-employed nihilogony ignores the several strands of research the modern paradigm ties together. Each of these strands brings with it its own concepts and framings. For example, Figure~\ref{fig:4645} shows one community of papers that was very small pre-216. Even in this one, we can see research that began with an interest in cognition in its most general terms, then in the impact of branding on pharmaceuticals. From there, it moves into how social media users talk about autism, until containing the misinformation research recognizable today. Figure~\ref{fig:1085} shows another, similar community of papers, this one moving from pre-2016 questions of different kinds of health literacy in the public (e.g. mental health or cord blood banking), to questions of social media monitoring and fact checking.


\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{network-img/1085.pdf}
\caption{An example community's (\#1085) population (2011-2023), showing how research on relationships with healthcare moves toward social media misinformation over time.}
\label{fig:1085}
\end{figure}

If, instead of looking at the biggest communities of 2023 back through time, we take the two biggest ones of every year and plot those through the duration of our dataset, we find that, of the pre-2016 strands, community \#1432 is the biggest and most well-established. This is the community associated with the aforementioned ``misinformation effect'' (see Section~\ref{intro}). It maintains a steady size across these years, even as topics like ``fake news'' and ``covid'' rose in popularity and prominence around it. These papers primarily work in psychology, with a particular focus on the effects of misinformation on memory.

\#1432's top TF-IDF terms (``ethical,'' ``debriefing,'' ...) may, at first, seem unrelated to those of the pre-2016 research found in Figure \ref{fig:tf}. To make the connection, consider this abstract from our database, from~\citet{otgaar_protecting_2020}, in a paper titled ``Protecting Against Misinformation: Examining the Effect of Empirically Based Investigative Interviewing on Misinformation Reporting,'' published in \textit{Journal for Police and Criminal Psychology}. Our community detection put this paper in community \#1432.

\begin{quote}
    Children who are involved in legal cases are often interviewed about events they witnessed or that might have happened to them. [...] We found that children’s recall during the NICHD interview protected children against the incorporation of misinformation in their accounts of the event [...] The current experiment suggests that evidence-based investigative interviewing can inoculate children’s memory against the corrupting impact of misinformation.
\end{quote}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/communities-graph.pdf}
\caption{Similar to Figure \ref{fig:23comms}, this is number of papers per year from the two biggest communities in each year in the dataset. Note that the same community often appears in the top 2 for many years, which is why there are fewer than might be expected). Each community is again labeled with its top TF-IDF terms. For the rest of the TF-IDF terms, see Table \ref{tab:tfidf-comms}}
\label{fig:communities}
\end{figure}

In our database, \#1432 is the only well-established pre-2016-paradigm strain of misinformation research, one that explains the pre-2016 frequency shifts in terms. It is being incorporated into the modern paradigm in two senses: Its research is increasingly similar to that of other misinformation paradigm papers, and its concepts and framings can be seen influencing the other paper-communities.

\begin{table*}
  \centering
  \input{citations-img/example_citations.tex}
\label{table:citations}
\caption{
An example of citations flowing from outside-\#1432 papers ``sources'' to inside-\#1432 ``targets.''  The former's titles tend towards language and framings more familiar to today's misinformation paradigm, and the latter's tend towards framing from the perspective of individual cognition. However, the two show clear overlapping interests and mutual engagement.
}
\end{table*}

Figure \ref{fig:citations} shows a small amount citations flowing into \#1432 from other communities. The small number is, in part, an artifact of our data, because \#1432 is a smaller community that the others in that figure, but also because our data collects only papers with ``misinformation'' in metadata, and the influence often flows through other concepts. 

Table~\ref{table:citations} contains a selection of papers outside community \#1432 citing papers within it. \#1432 papers tend to concern themselves primary with the individual, cognitive effects of having heard misinformation, whereas odern misinformation researchers might more typically focus on how it circulates in social media. These are complimentary views, often examining identical phenomena from slightly different perspectives. For example, \citet{brashierAgingEraFake2020}'s ``Aging in an Era of Fake News'' examines the susceptibility of older adults to misinformation on social media.

Sometimes, the different provenances of ideas cause friction. Consider the response from \citet{hymanMisinformationWorldviewsPosttruth2017} to \citet{lewandowskyMisinformationUnderstandingCoping2017}. From the former:

\begin{quote} 
    Based on combating misinformation, Lewandowsky et al. made narrow recommendations for future cognitive research, including the generalization of inoculation techniques [...] Unfortunately, while Lewandowsky et al. acknowledged that world views matter, they argued against addressing worldviews. They stated that for corrections to be effective “they must not directly challenge people’s worldview” [...] [They] were concerned with the ethical implications that come with trying to modify individuals’ world views. Therefore, Lewandowsky et al. argued that “worldview ought to be decoupled from the propensity to accept misinformation and resist its correction”.
  \end{quote}

The modern misinformation paradigm is intertwined with electoral politics and social media. In that context, changing people's worldviews, or perhaps stopping them from being changed by unscrupulous actors, is core to the whole project. \#1432's work, however, brings an emphasis on factual eye witness accounts in therapy sessions or courtrooms. 


Despite some friction, these conceptions of misinformation are, by and large, complimentary, allowing for bridging concepts. They are both, for example, interested in the efficacy of different strategies for stopping people from believing misinformation, or of ``prebunking''/``inoculating against misinformation'' (as the examples in Table \ref{table:citations} call it). In papers like \citet{gradyNeverthelessPartisanshipPersisted2021}'s ``Nevertheless, Partisanship Persisted: Fake News Warnings Help Briefly, but Bias Returns with Time'' and \citet{murphyFalseMemoriesFake2019}'s ``False Memories for Fake News During Ireland's Abortion Referendum'' (both co-authored by Loftus), we see research that more comfortably fuses the concerns of today's misinformation paradigm of fake news and bias with the older focus on the cognitive effects of the misinformation. 


Modern misinformation research has studied the effects of fake news on memory or belief formation enough that there are literature reviews on that specific subtopic, and they specifically cite Loftus's work.~\cite{faedda_fake_2024} We can also detect signs of these more diffuse indicators of influence in our database, where we find 157 papers matching the regex \texttt{.*[ -]formation.*}, the majority of which are discussing ``belief formation,`` ''opinion formation,'' etc. Of these, only ten are from community \#1432, suggesting conceptual ties that extend beyond what the citation flows might show.

We can see these same patterns in Loftus's own work. In a paper titled ``From Primary to Presidency: Fake News, False Memory, and Changing Attitudes in the 2016 Election,'' Loftus and her co-authors give an example of the old paradigm fully intertwined with the new one~\cite{grady_primary_2023}. From their abstract:

\begin{quote}
    [...] This study followed 602 United States citizens, recruited from Amazon Mechanical Turk, at three points throughout the 2016 presidential election investigating how attitudes and preferences changed over time and how people remembered their past feelings. Across political parties, people’s memory for their past attitudes was strongly influenced by their present attitudes; more specifically, those who had changed their opinion of a candidate remembered their past attitudes as being more like their current attitudes than they actually were. Participants were also susceptible to remembering false news events about both presidential candidates. However, they were largely unaware of their memory biases...
\end{quote}

This is a classic Loftus experimental setup, but merging with the new language of fake news and data-gathering through clickwork services, a common practice in computer science research.

\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{img/citations.png}
\caption{Citation network and source/target heat map illustrating citation patterns between key research communities. The sizes of the nodes and edges represent the size of the communities and the number of citations respectively.}
\label{fig:citations}
\end{figure}

\section{Discussion}
\label{discussion}

\subsection{Historical Context and Parallels}

With one major caveat, which is the principle subject of this paper, the results discussed in Section~\ref{results} are ultimately similar to those of from \citet{broda_misinformation_2024}:

\begin{quote}
In the case of misinformation, disinformation, and fake news, it also appears as if different strands of literature have developed quite independently of each other. The result is a rather scattered body of work.
\end{quote}

We found, in agreement with the above, that these big communities of papers are mostly self-citing, and, if they existed at all before 2016, it was in some primordial state. This also agrees with many other reviews and histories, many of which explicitly link the concept to social media, even when they gesture broadly to vague historical context~\cite{donovan_express_2025,perez-escolar_systematic_2023,miro-llinares_misinformation_2023}. 

In community \#1432, however, we find a caveat that, to our knowledge, goes unnoticed in other reviews and histories of misinformation. This is a strain of research that much predates 2016, one that was not just established prior to the beginning of our dataset (2011), but that had played a prominent role in public life. 

Its history begins in 1980, when Michelle Smith co-authored \textit{Michelle Remembers} with her psychiatrist and soon-to-be-husband, Lawrence Pazder. In it, she recounts her gruesome experience being tortured at the hands of a Satanic cult, memories that, until recently, she had repressed. Pazder had used modern psychiatric techniques to help her recover these lost memories. These stories turned out to be grotesque fabrications, but the book, along with its credulous media coverage, triggered what became known as the Satanic Panic, in which innocent daycare workers, members of the LGBT+ community, and others were convicted of ritual child abuse~\cite{hearst_qanon_2022,shewan_conviction_2015}.

 As discussed in Section \ref{intro}, Elizabeth Loftus, \#1432's most cited author, studies the ``misinformation effect.'' Much of this research was a response to, as Loftus put it in 1993,~\cite{loftus_reality_1993} ``a rise in reported memories of childhood sexual abuse that were allegedly repressed for many years.'' Her work explicitly references the Satanic panic, and considers not just the cognitive phenomenon of the misinformation effect, but, from the abstract from that same 1993 paper...

\begin{quote}
    (a) How common is it for memories of child abuse to be repressed? (b) How are jurors and judges likely to react to these repressed memory claims? (c) When the memories surface, what are they like? and (d) How authentic are the memories? 
  \end{quote}

Loftus was a prominent skeptic of the recovered-memory therapy behind the Satanic Panic of the 1980's and 90's and has continued to publish on memory, narrative, and misinformation~\cite{noauthor_elizabeth_2025}. More recently, she has published work considering ``fake news'' as potentially influencing false memories, e.g. ``Misinformation–past, present, and future''~\cite{loftus_misinformation_2024}.


It would be an oversimplification to say she was inspired to do this research because of the Satanic Panic. As previously discussed, her work on these issues began in the early 1970's, predating it. Likewise, as Figure \ref{fig:23comms} shows, today's misinformation paradigm does not come from nothing. Authors like~\citet{nguyen_sources_2012} were already investigating sources of misinformation on social media. In both cases, social changes met with researchers' prior interests, and the two mutually affected each other, creating and growing a paradigm of public interest. The modern misinformation paradigm comes at a time when people who believe that the world is run by a cabal of child-torturing pedophiles (i.e. Qanon) are a powerful political movement, forming a core part of the current US administration's coalition, and whose influence has penetrated deep into public life~\cite{feeld_qanon_2025}.

Because Qanon is a social media phenomenon, and because the misinformation paradigm was, in a measurable sense, born in 2016 (see Figure~\ref{fig:tf}~and~\ref{fig:23comms}, it makes sense to begin its history there.To view the field this way, however, is to deprive its practitioners of valuable historical context, one with striking parallels to today, a rich vein from which we can mine insights about the role of science in public life, and even about its relationship to new forms of mass media. More specifically, we note the following parallels. Then as now...
\begin{itemize}
  \item ... a technical advance in one of the day's most prominent fields (the Cognitive Revolution and the Digital one) was at least the proximate cause to a social crisis.
    \item ... the crisis was linked to recent innovations in mass media~\cite{hearst_qanon_2022}.
  
    \item ... researchers sought to understand and combat the harm, often within the field itself, and often participating both in public debate and in the very social processes they study. Misinformation literature in computer science journals, for example, often proposes ways to automatically detect misinformation on social media~\cite{broda_misinformation_2024} while also seeing misinformation as a social media phenomenon. Likewise, Loftus has participated in the legal system, often as an expert witness for the defense in high profile trials.~\cite{shewan_conviction_2015}.

    \item ... misinformation research responded to the politically-contested nature of our shared social reality. Modern misinformation research often discusses this by noting the so-called ``post-truth'' era, a term that appears in abstracts 133 times in our database.
    \item ... there was widespread social concern that  powerful malevolent forces are murdering innocent children~\cite{hearst_qanon_2022}~\cite{shewan_conviction_2015}.
\end{itemize}

\subsection{The Concept of ``Misinformation''}

As discussed in Section~\ref{results}, these parallels are not a coincidence. Today's paradigm inherits from many predecessors across many fields. Community \#1432 is one of many strands of research now woven together. We have focused on it because, of the primordial soup from which the modern conception of misinformation emerged, it was the most established, and, as we have argued, it is often excluded.

Just as important in this bundle of ideas is what is not included. MEDIA STUDIES GOES HERE

These influences make up a concept of misinformation that is not at all obvious. At its core is a focus on an individual reading a piece of text. ADD POLITICAL ECONOMY AND CORPORATE INTERESTS HERE

Future work might focus on the many other threads that have woven together into what ``misinformation'' means today.

\subsection{Limitations}
\label{limitations}

With the exception of citations, all our data comes from a Scopus export. Much computational social science work relies on data derived from opaque, proprietary systems, and therefore risks systematic distortion~\cite{poudelCuratedRealitiesIntersection2025}. In our case, Scopus's search is opaque to us. Our arguments, however, rely on the existence of the data, especially the pre-2016 data, not necessary its completeness.

Our methodology also depends entirely on the keyword ``misinformation.'' It could have been that researchers using the modern misinformation paradigm simply happened upon the same term as those in group \#1432 with no conceptual ties. Conversely, researchers might have used a different term entirely while drawing heavily on \#1432's  work, either directly or indirectly. We have argued that there is a lineage, showing ties that extend beyond citations, but through the concepts discussed in various papers. 

Finally, our analysis restricted itself to the academic literature. As Figure~\ref{fig:twitter} shows, the term's meteoric rise in popularity is in no way restricted to the academy. Though impossible to compare directly due to their fundamentally different temporal characteristics, comparing Figure~\ref{fig:twitter} to ~\ref{fig:tf} suggests that these either developed in parallel, or it could be that academics brought the term from other parts of public life.  We hope, in future work, to further explore how and why the term ``misinformation'' came to define the paradigm. Doing so would require an analysis that extends beyond journal articles.


\subsection{Conclusion}

As the TF-IDF terms in Table~\ref{tab:tfidf-comms} show, many of the papers in our database warn of democracy under threat, or of distrust in science and/or institutions. Some authors argue that misinformation and distrust institutions are linked~\cite{akyuz_impact_2021}, or that misinformation causes distrust in institutions~\cite{stetka_have_2025}. To our knowledge, it is much less common to question whether our institutions have earned the public trust, and, if not, how our institutions ought to behave when confronted with the politically-contentious nature of reality.

In the history of misinformation, we see the institutional reality of science through both its successes and its failures. Scientific techniques gave us \textit{Michelle Remembers}, and skeptics in the scientific community took to testing whether these memory techniques were indeed reliable. Lest anyone think that this story is a simple one of the scientific method working as intended, one in which dispassionate scientists debunk a bad hypothesis, the way that science is often said to work, Loftus is a controversial figure. In her career as a public intellectual, she has, for example, provided expert testimony on the unreliability of memories for Harvey Weinstein's~\cite{press_harvey_2020}, Ted Bundy's~\cite{marsh_how_2012}, and Ghislaine Maxwell's~\cite{news_ghislaine_2021} defenses. Going beyond Loftus, though recovered memory therapies are now debunked, the ``Memory Wars'' are not definitively settled, and, as the scientific debate goes on, innocent people's lives have been shattered by the ideas it generated~\cite{shewan_conviction_2015}. As Theodore Porter puts it, 'The role of the sciences in regard to public issues of all kinds has never been more encompassing.' Juries depend on scientists to know if witnesses are reliable, and psychiatric theories are deployed on patients seeking help in their most vulnerable moments. This makes ``the divide between technical science and political opinion is highly unstable.''~\cite{porter_how_2009}. 

To that end, over 1500 papers in our database discuss misinformation detection, a popular idea in the scientific literature~\cite{broda_misinformation_2024} that would necessarily rely on social media companies for its implementation. This research places science in a technical role at the interstices of politically-charged social functions, one that once again has historical parallels, this time in Loftus's expert testimony in the courtroom. 

We mention Loftus's work on legal defenses only to illustrate the complex role of the scientist in public life. Despite the recent success enjoyed by its opponents, to speak with the authority of science is still to wield considerable power. The history of misinformation, we argue, gives lie to the pretense of science as dispassionate technicality. As Porter puts it, ``When science denies its own depth in favor of pretending to the straightforward application of method and the production of information, it participates ironically in the anti-intellectualism it otherwise purports to combat.''~\cite{porter_how_2009}

\section{References}
\bibliography{refs}

\end{document}
