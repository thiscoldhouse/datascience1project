\documentclass[                                                                            
 reprint,                                                                                  
 amsmath,amssymb,                                                                          
 apsf
]{revtex4-2}

\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{booktabs}
\usetikzlibrary{arrows.meta, positioning}

\newcommand\todo[1]{\textcolor{red}{#1}}

\selectlanguage{english}

\definecolor{darkbg}{RGB}{15, 18, 25}
\definecolor{lighttext}{RGB}{247, 247, 255}
\definecolor{accent}{RGB}{211, 63, 73}


\date{\today}

\begin{document}

\title{``Misinformation'' Before and After 2016: the Impact of Its Satanic Panic Lineage}

\author{Ale}
\author{Danny}
\author{Jeremy}

\date{\today}
\begin{abstract}
    We trace the history of the term ``misinformation'' through the years 2011-2023 in the academic literature. In agreement with previous research, we find that the modern misinformation paradigm formed around 2016. However, in analyzing the changing language in the literature before and after 2016, we find that most histories and literature reviews fail to account for our pre-2016 findings. 
    % I think what comes after "account for" should be specific. Otherwise the sentence is kind of tautological.
    We fill the gap by identifying a consistent strand of ``misinformation'' research that can be traced back to the Satanic Panic of the 1980s, and we argue that today's misinformation research owes more to this intellectual lineage than is generally acknowledged. We conclude by drawing parallels between the Satanic Panic and today, and, similarly, between ``misinformation'' research then and now.
\end{abstract}

\maketitle


% ------------------------------------------------------------
\section{Introduction}

It is inarguable that people say things that are not true, whether on social media or otherwise. That people often believe these things, both to individual and collective detriment, is likewise self-evident. Since 2016, in both formal and inforaml settings, we have described this phenomenon with the term ``misinformation'' (see Figure \ref{fig:twitter}). In the academic literature, it has come to represent a new scientific paradigm, which, like any paradigm, comes with its own history and assumptions~\cite{kuhn_structure_1962}.

As always, with a new paradigm's success comes a re-interpretation of previously-known facts. ``Misinformation'' has, for example, been used to describe events in Rome~\cite{posetti_short_2018}, and even the activities of fish and other animals~\cite{fahimipour_wild_2023}. The paradigm's penetration into public life means that such studies can garner attention in the popular press~\cite{times_evolution_2025}.

Previous work shows that the modern misinformation paradigm dates to roughly 2016, and that its existence is intertwined with the rise of social media ~\cite{broda_misinformation_2024,donovan_express_2025}. These histories tend to begin as we did,
% But we didn't do that here? So what do you mean by "as we did"?
with a general statement on the vast history of people saying and believing untrue things. They often cite technological upheavals in media as important factors, then specifically turn their focus to social media. We build upon those accounts of the post-paradigm history here. By analyzing academic papers published between 2011 and 2023 with the keyword ``misinformation'' in their metadata, we identify pre-2016 patterns unaccounted for in these histories. %You should cite which histories you mean?

We fill this gap by identifying an academic tradition that predates today's misinformation research, and stretches back to the ``memory wars'' and the Satanic Panic in the 1980s and 90s. It is a related but distinct body of work, one whose research output has remained steady while other work on misinformation has greatly expanded around it, and is easily missed in the sheer volume of post-2016 research. We show that today's misinformation research owes more to this lineage than is generally acknowledged, and that current work directly drawing on the older version of the paradigm, while still distinct, is increasingly influenced by the modern version. % Not the clearest sentence, we should figure out how to say this better.

We conclude by noting the historical parallels between both the historical contexts of these paradigms and the paradigms themselves. %Wat?
Both came about in moments of mass panic about evil forces doing harm to children, fueled by a changing media and political context. We are by no means the first to note the historical parallels between Qanon and the Satanic Panic, and we are much indebted to prior scholarship on this issue~\cite{hearst_qanon_2022}. Instead, our contribution is to note that, just as ~\citet{hearst_qanon_2022} finds that modern conspiricism has roots in the Satanic Panic, so too can we trace the modern scientific response back to that of the 1980s. We hope that, by bringing this context to the fore, the scientific community can better navigate these moments of extreme turbulence in the politically contested nature of our shared reality.

\begin{figure}[H]
\label{fig:twitter}
\centering
\includegraphics[width=\linewidth]{misc-img/storywrangler.pdf}
\caption{Frequency of usage of the word ``misinformation'' on Twitter~\cite{alshaabi2021storywrangler}. Note the rise precisely at the US election in 2016.}
\end{figure}

\section{Data and Methods}

Our primary database is a Scopus.com export of all papers with ``misinformation'' in any metadata from 2011–2023. We supplemented that with the opencitations.net API.

\subsection{Term Frequency}

We split our corpus into two case-insensitive bags of words (BOWs): One using all titles and abstracts from the years 2011-2015; the second from 2017 onward. When tokenizing, we generated a list of the 400 most-frequent bigrams in our corpus and kept those as one token. We stripped punctuation, the most common stopwords, and some stopwords specific to our corpus \footnote{Those words are: elsevier, rights, reserved, mesh, taylor, francis, copyright, llc, bt, lftb, springer, ieee, information, misinformation. The last 2 were removed because they were present in almost every document.}

We calculated the frequency of every token in both BOWs, then chose the 9 smallest (i.e. most negative) and largest differences of frequency from the first to the second. We then classified all papers as having at least one word from either set or one of both, the results of which are in Figure \ref{fig:tf} and discussed in Section \ref{results}.


\subsection{Communities}

For the community labels, we created a network of papers with each edge representing an author; two papers are connected if they share an author. To avoid small-world problems from the small number of papers with many authors, the weight of the edge between two papers $P_1$ and $P_2$ was defined as

$$W(P_1, P_2) = \frac{1}{len(P_1.\text{authors}) \times len(P_2.\text{authors})}$$

We ran Louvain community detection to create the Community labels.\footnote{We went with the default resolution of 1. Changing the resolution had a minimal effect on our analysis because it mostly affected the smaller communities and we are interested in the larger ones.} Our community labels represent a community of papers linked by common authors, not a more traditional (and intuitive) community of authors linked by common papers. We are less interested in the institutional dynamics of misinformation scholars than the history of a concept.

Our algorithm labeled 8033 distinct communities. 6797 are communities of just one paper, and the average number of papers in a community is 1.66. We looked at the two biggest paper-communities in every year, as well as all the biggest communities in 2023, and analyzed the citation flows between communities, which we show in Figure \ref{fig:citations} and discuss in Section \ref{results}.

\section{Results}
\label{results}

After 2016, there is an explosion of the use of the word ``misinformation'' in academic literature. In 2011, the first year in our dataset, there were only 118 papers containing the term anywhere in their metadata. In 2023, there were 3380, or 28 times as many, and the post-2016 corpus contains 20 times as many papers as the pre-2016 one.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/fig.pdf}
\caption{Words with largest absolute frequency shifts before and after 2016 are on the right. We tagged all papers as having one from either or one of each. The top-left graph shows papers that have at least one word from that set of words as an annual percentage (some papers use both, so percentages do not add up to 100\%); the bottom one is the raw counts of all papers in the data.}
\label{fig:tf}
\end{figure}

Looking at tokens with the largest absolute frequency shift (Figure \ref{fig:tf}), the post-2016 words are those that we in 2025 expect in misinformation literature, like ``social media,'' ``pandemic,'' ``fake news,'' etc. As discussed in our introduction, these findings on the post-2016 explosion, as well as the topics of study (e.g. social media and the pandemic), are similar to those found in literature reviews~\cite{broda_misinformation_2024}, histories of misinformation~\cite{donovan_express_2025}, and academic summaries~\cite{posetti_short_2018} of the misinformation literature.

To our knowledge, however, the pre-2016 terms remain largely unexplained in misinformation histories and literature reviews. For example, in their literature review, ~\citet{broda_misinformation_2024} used a similar date range in their analysis as our own (2010-2021). Their dataset comes from Google Scholar, and they used keywords ``misinformation,'' ``disinformation,'' and ``fake news.'' They too find a similar explosion in the literature, and on a similar timeline, but their summary does not account for words like ``women,'' ``children,'' ``memory,'' and ``recall,'' though there are hints of the same phenomenon. When they break down the disciplines in which misinformation research is published, they find that the top 5 are Communication, Computer Science, Psychology, Political Science, and Economics. They note that the research in Psychology journals tends to focus on experiments, and that these experiments show broad themes. We discuss this in Section \ref{discussion}.


\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{network-img/4645.pdf}
\caption{An example of community \#4645's population (2011-2023), showing how human behavior research moves toward misinformation on social media over time.}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{network-img/1085.pdf}
\caption{An example community's (\#1085) population (2011-2023), showing how research on relationships with healthcare moves toward social media misinformation over time.}
\end{figure}

In short, we find that most summaries of the field tell its history as show in Figure \ref{fig:23comms}: They look at the most prominent strains of research today, then trace them back to their origin. Their analyses then flow from there. As a result, some histories explicitly define their inquiry to start with social media, defining a concept like ``misinformation-at-scale''~\cite{donovan_express_2025}.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/first-communities.pdf}
\caption{The number of papers in the top 10 paper-communities throughout the duration of our dataset. Each community is labeled with its top TF-IDF terms.}
\label{fig:23comms}
\end{figure}

\input{tables0.tex}

To explain the pre-2016 terms, instead of looking at the biggest communities of 2023 and looking back, we take the two biggest ones of every year and plot those through the duration of our dataset. Figure \ref{fig:communities} shows one community, \#1432, which maintains a steady size across these years, even as topics like `fake news' and `covid' rose in popularity and prominence around it. These papers primarily work in psychology, with a particular focus on memory and misinformation.

\#1432's top TF-IDF terms (``ethical,'' ``debriefing,'' ...) may, at first, seem unrelated to those of the pre-2016 research found in Figure \ref{fig:tf}. To make the connection, consider this abstract from our database, from ~\citet{otgaar_protecting_2020}, in a paper titled ``Protecting Against Misinformation: Examining the Effect of Empirically Based Investigative Interviewing on Misinformation Reporting,'' published in \textit{Journal for Police and Criminal Psychology}. Our community detection put this paper in community \#1432.

\begin{quote}
    Children who are involved in legal cases are often interviewed about events they witnessed or that might have happened to them. [...] We found that children’s recall during the NICHD interview protected children against the incorporation of misinformation in their accounts of the event [...] The current experiment suggests that evidence-based investigative interviewing can inoculate children’s memory against the corrupting impact of misinformation.
\end{quote}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{img/communities-graph.pdf}
\caption{Similar to Figure \ref{fig:23comms}, this is number of papers per year from the two biggest communities in each year in the dataset. Note that the same community often appears in the top 2 for many years, which is why there are fewer than might be expected). Each community is again labeled with its top TF-IDF terms. For the rest of the TF-IDF terms, see Table \ref{tab:tfidf-comms}}
\label{fig:communities}
\end{figure}

Community \#1432, then, is mostly papers about the (un)reliability of memory, often in legal settings, and often involving witnesses like children or victims. Its most cited author, Elizabeth Loftus, co-authored 37 papers on the topic between 2011 and 2023. Her work on memory and misinformation stretches back to 1974's, ``Reconstruction of automobile destruction: An example of the interaction between language and memory'' ~\cite{loftus_reconstruction_1974}. By 1989, she was doing work explicitly focused on ``misinformation'' such as ``Misinformation and memory: the creation of new memories'' ~\cite{loftus_misinformation_1989}.

Loftus was a prominent skeptic of the recovered-memory therapy behind the Satanic Panic of the 1980's and 90's and has continued to publish on memory, narrative, and misinformation ~\cite{noauthor_elizabeth_2025}. More recently, she has published work considering ``fake news'' as potentially influencing false memories, e.g. ``Misinformation–past, present, and future'' ~\cite{loftus_misinformation_2024}.

% Would stuff about Loftus make more sense to discuss later, after Michelle Remembers?

\begin{figure}[H]
\centering
\includegraphics[width=1\linewidth]{img/citations.png}
\caption{Citation network and source/target heat map illustrating citation patterns between key research communities. The sizes of the nodes and edges represent the size of the communities and the number of citations respectively.}
\label{fig:citations}
\end{figure}

\section{Discussion}
\label{discussion}

\subsection{Historical Context and Parallels}

With one major caveat, our findings are ultimately similar to those of Broda et al.
\begin{quote}

In the case of misinformation, disinformation, and fake news, it also appears as if different strands of literature have developed quite independently of each other. The result is a rather scattered body of work.~\cite{broda_misinformation_2024}
\end{quote}

We found, in agreement with the above, that these big communities of papers are mostly self-citing, and, if they existed at all before 2016, it was in some primordial state. This also agrees with many other reviews and histories, many of which explicitly link the concept to social media, even when they gesture broadly to vague historical context ~\cite{donovan_express_2025,}~\cite{perez-escolar_systematic_2023}~\cite{miro-llinares_misinformation_2023}. 

In community \#1432, however, we find an important caveat that, to our knowledge, goes unnoticed in other reviews and histories of misinformation. This is a strain of research that much predates 2016, one that was not just established prior to the beginning of our dataset (2011), but that had played a prominent role in public life. We argue that this provides important historical context for existing misinformation research.

Its history begins in 1980, when Michelle Smith co-authored \textit{Michelle Remembers} with her psychiatrist and soon-to-be-husband, Lawrence Pazder. In it, she recounts her gruesome experience being tortured at the hands of a Satanic cult, memories that, until recently, she had repressed. Pazder had used modern psychiatric techniques to help her recover these lost memories. These stories turned out to be grotesque fabrications, but the book, along with its credulous media coverage, triggered what became known as the Satanic Panic, in which innocent daycare workers, members of the LGBT+ community, and others were convicted of ritual child abuse ~\cite{hearst_qanon_2022,}~\cite{shewan_conviction_2015}.

 As discussed in Section \ref{results}, Elizabeth Loftus, \#1432's most prolific and cited author, studies the ``misinformation effect.'' Her experiments often involve asking a subject to recall something, but, in the process, attempting to influence that memory in some way, perhaps by implication in the phrasing of her question. Much of this research was a response to, as Loftus put it in 1993,~\cite{loftus_reality_1993} ``a rise in reported memories of childhood sexual abuse that were allegedly repressed for many years.'' Her work explicitly references the Satanic panic, and considers not just the cognitive phenomenon of the misinformation effect, but, from the abstract from that same 1993 paper...

\begin{quote}
    (a) How common is it for memories of child abuse to be repressed? (b) How are jurors and judges likely to react to these repressed memory claims? (c) When the memories surface, what are they like? and (d) How authentic are the memories? 
\end{quote}

It would be an oversimplification to say she was inspired to do this research because of the Satanic Panic. As previously discussed, her work on these issues began in the early 1970's, predating it. Likewise, as Figure \ref{fig:23comms} shows, today's misinformation paradigm does not come from nothing. Authors like ~\citet{nguyen_sources_2012} were already investigating sources of misinformation on social media. In both cases, social changes met with researchers' prior interests, and the two mutually affected each other, creating and growing a paradigm of public interest.

The modern misinformation paradigm comes at a time when people who believe that the world is run by a cabal of child-torturing pedophiles (i.e. Qanon) are a powerful political movement, forming a core part of the current US administration's coalition, and whose influence has penetrated deep into public life~\cite{feeld_qanon_2025}. Qanon is a social media phenomenon, and it perfectly exemplifies the kinds of phenomena misinformation researchers today, using the tools of science, wish to understand. It is therefore unsurprising that, setting aside aforementioned vague statements about the history of false beliefs, the field's history of itself is functionally a nihilogony.

To view the field this way, we argue, is to deprive its practitioners of its historical context, one with striking parallels to today, a rich vein from which we can mine insights about the role of science in public life, and even about its relationship to new forms of mass media. More specifically, we note the following parallels. Then as now...
\begin{itemize}
  \item ... a technical advance in one of the day's most prominent fields (the Cognitive Revolution and the Digital one) was at least the proximate cause to a social crisis.
    \item ... the crisis was linked to recent innovations in mass media ~\cite{hearst_qanon_2022,}.
  
    \item ... researchers sought to understand and combat the harm, often within the field itself, and often participating both in public debate and in the very social processes they study. Misinformation literature in computer science journals, for example, often proposes ways to automatically detect misinformation on social media~\cite{broda_misinformation_2024} while also seeing misinformation as a social media phenomenon. Likewise, Loftus has participated in the legal system, often as an expert witness for the defense in high profile trials. ~\cite{shewan_conviction_2015}.

    \item ... misinformation research responded to the politically-contested nature of our shared social reality. Modern misinformation research often discusses this by noting the so-called ``post-truth'' era, a term that appears in abstracts 133 times in our database.
    \item ... there was widespread social concern that  powerful malevolent forces are murdering innocent children ~\cite{hearst_qanon_2022}~\cite{shewan_conviction_2015}.
\end{itemize}

These parallels are not a coincidence. Instead, both the misinformation phenomenon~\cite{hearst_qanon_2022,} and today's paradigm inherit from their predecessors. Our analysis in Figure \ref{fig:citations} showed some (but not much) citation flow into \#1432 from other communities. This is, in part, an artifact of our data, because \#1432 is smaller community that the others in that figure, but also because our data collects only papers with ``misinformation'' in metadata, and the influence often flows through other concepts. 

For example, modern misinformation researchers have studied the effects of fake news on memory or belief formation enough that there are literature reviews on that specific subtopic, and they specifically cite Loftus's work.~\cite{faedda_fake_2024} We can also detect signs of these more diffuse indicators of influence in our database, where we find 157 papers matching the regex \texttt{.*[ -]formation.*}, the majority of which are discussing ``belief formation,`` ''opinion formation,'' etc. Of these, only ten are from community \#1432, suggesting conceptual ties that extend beyond what the citation flows might show.

Loftus herself has participated in modern misinformation research ~\cite{grady_primary_2023}. In a paper titled ``From Primary to Presidency: Fake News, False Memory, and Changing Attitudes in the 2016 Election,'' Loftus and her co-authors give an example of the ghost of the old paradigm still living through the new one. From their abstract:

\begin{quote}
    [...] This study followed 602 United States citizens, recruited from Amazon Mechanical Turk, at three points throughout the 2016 presidential election investigating how attitudes and preferences changed over time and how people remembered their past feelings. Across political parties, people’s memory for their past attitudes was strongly influenced by their present attitudes; more specifically, those who had changed their opinion of a candidate remembered their past attitudes as being more like their current attitudes than they actually were. Participants were also susceptible to remembering false news events about both presidential candidates. However, they were largely unaware of their memory biases...
\end{quote}

This is a classic Loftus experimental setup, but merging with the new language of fake news and data-gathering through clickwork services, a common practice in computer science research.

\subsection{Limitations}

Our methodology depends entirely on the keyword ``misinformation.'' It could have been that researchers using the modern misinformation paradigm simply happened upon the same term as those in group \#1432 with no conceptual ties. Conversely, researchers might have used a different term entirely while drawing heavily on \#1432's  work, either directly or indirectly. We have argued that there is a lineage, making the conceptual ties through our qualitative research. % What do you mean by qualitative research here?
In future work, we hope to further explore how exactly the term ``misinformation'' came to be. 

% I think order of paper hops around? Let's reorganize.
% Let's give some examples of where you see connection between satanic panic lit and post-2016 lit. And give examples of how misinformation as on social media is infiltrating the other strains. Like more quotes, more discussion to support those two prongs.

\subsection{Conclusion}

As the TF-IDF terms in Table \ref{tab:tfidf-comms} show, many of the papers in our database warn of democracy under threat, or of distrust in science and/or institutions. Some authors argue that misinformation and distrust institutions are linked~\cite{akyuz_impact_2021}, or that misinformation causes distrust in institutions ~\cite{stetka_have_2025}. To our knowledge, it is much less common to question whether our institutions have earned the public trust, and, if not, how our institutions ought to behave when confronted with the politically-contentious nature of reality.

In the history of misinformation, we see the institutional reality of science through both its successes and its failures. Scientific techniques gave us \textit{Michelle Remembers}, and skeptics in the scientific community took to testing whether these memory techniques were indeed reliable. Lest anyone think that this story is a simple one of the scientific method working as intended, one in which dispassionate scientists debunk a bad hypothesis, the way that science is often said to work, Loftus is a controversial figure. In her career as a public intellectual, she has, for example, provided expert testimony on the unreliability of memories for Harvey Weinstein's~\cite{press_harvey_2020}, Ted Bundy's ~\cite{marsh_how_2012}, and Ghislaine Maxwell's~\cite{news_ghislaine_2021} defenses. Going beyond Loftus, though recovered memory therapies are now debunked, the ``Memory Wars'' are not definitively settled, and, as the scientific debate goes on, innocent people's lives have been shattered by the ideas it generated ~\cite{shewan_conviction_2015}. As Theodore Porter puts it, 'The role of the sciences in regard to public issues of all kinds has never been more encompassing.' Juries depend on scientists to know if witnesses are reliable, and psychiatric theories are deployed on patients seeking help in their most vulnerable moments. This makes ``the divide between technical science and political opinion is highly unstable.'' ~\cite{porter_how_2009}. 

To that end, over 1500 papers in our database discuss misinformation detection, a popular idea in the scientific literature ~\cite{broda_misinformation_2024} that would necessarily rely on social media companies for its implementation. This research places science in a technical role at the interstices of politically-charged social functions, one that once again has historical parallels, this time in Loftus's expert testimony in the courtroom. 

We mention Loftus's work on legal defenses only to illustrate the complex role of the scientist in public life. Despite the recent success enjoyed by its opponents, to speak with the authority of science is still to wield considerable power. The history of misinformation, we argue, gives lie to the pretense of science as dispassionate technicality. As Porter puts it, ``When science denies its own depth in favor of pretending to the straightforward application of method and the production of information, it participates ironically in the anti-intellectualism it otherwise purports to combat.'' ~\cite{porter_how_2009}

\section{References}
\bibliography{refs}

\end{document}
